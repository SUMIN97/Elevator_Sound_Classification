{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "def get_melspectrogram_db(file_path, sr=None, n_fft=2048, hop_length=512, n_mels=128, fmin=20, fmax=8300, top_db=80):\n",
    "    wav,sr = librosa.load(file_path,sr=sr)\n",
    "    if wav.shape[0]<5*sr:\n",
    "        wav = np.pad(wav,int(np.ceil((5*sr-wav.shape[0])/2)),mode='reflect')\n",
    "    else:\n",
    "        wav=wav[:5*sr]\n",
    "        spec=librosa.feature.melspectrogram(wav, sr=sr, n_fft=n_fft,hop_length=hop_length,n_mels=n_mels,fmin=fmin,fmax=fmax)\n",
    "        spec_db=librosa.power_to_db(spec,top_db=top_db)\n",
    "    return spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_to_image(spec, eps=1e-6):\n",
    "    mean = spec.mean()\n",
    "    std = spec.std()\n",
    "    spec_norm = (spec - mean) / (std + eps)\n",
    "    spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "    spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "    spec_scaled = spec_scaled.astype(np.uint8)\n",
    "    return spec_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Data(Dataset):\n",
    "    def __init__(self, wavs_path):\n",
    "       \n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.wavs_path = wavs_path\n",
    "        self.n_fft= int(1024)\n",
    "        self.hop_length= int(self.n_fft/4) #\n",
    "        self.top_db = 80\n",
    "        self.fmin = 20\n",
    "        self.fmax = 8300\n",
    "        self.sr = int(22050 * 1.0)\n",
    "       \n",
    "        \n",
    "        for path in tqdm(self.wavs_path):\n",
    "            self.labels.append(int(path.split('/')[-2]))\n",
    "            \n",
    "            wav, sr = librosa.load(path)\n",
    "            start_idx = 0\n",
    "            for i in range(wav.shape[0]):\n",
    "                if abs(wav[i]) < 0.025: continue\n",
    "                start_idx = i\n",
    "                break\n",
    "            wav_cut = wav[start_idx:start_idx + int(self.sr)]\n",
    "            shape = wav_cut.shape[0]\n",
    "            if  shape< self.sr:\n",
    "                wav_cut = np.pad(wav_cut,int(np.ceil((1* self.sr-shape)/2)),mode='constant')\n",
    "                wav_cut = wav_cut[: self.sr]\n",
    "            \n",
    "\n",
    "            if wav_cut.shape[0] !=  self.sr:\n",
    "                print(path, wav_cut.shape)\n",
    "                \n",
    "            spec=librosa.feature.melspectrogram(wav_cut, sr=self.sr, n_fft=self.n_fft,hop_length=self.hop_length, fmin=self.fmin, fmax=self.fmax)\n",
    "            spec_db=librosa.power_to_db(spec,top_db=self.top_db)\n",
    "            self.data.append(spec_to_image(spec_db))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "    \n",
    "    def spec_to_image(spec, eps=1e-6):\n",
    "        mean = spec.mean()\n",
    "        std = spec.std()\n",
    "        spec_norm = (spec - mean) / (std + eps)\n",
    "        spec_min, spec_max = spec_norm.min(), spec_norm.max()\n",
    "        spec_scaled = 255 * (spec_norm - spec_min) / (spec_max - spec_min)\n",
    "        spec_scaled = spec_scaled.astype(np.uint8)\n",
    "        return spec_scaled\n",
    "\n",
    "\n",
    "      \n",
    "          \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape, batch_size=16, num_category=20):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size = 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size = 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.conv4 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(256)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(256)\n",
    "        self.dense1 = nn.Linear(256*(((input_shape[1]//2)//2)//2)*(((input_shape[2]//2)//2)//2),500)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense2 = nn.Linear(500, num_category)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2) \n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.bn4(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(self.bn6(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2)\n",
    "        x = self.conv7(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.conv8(x)\n",
    "        x = F.relu(self.bn8(x))\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = F.relu(self.dense1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:0')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "    \n",
    "def setlr(optimizer, lr):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab/pytoch1.5/lib/python3.6/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d262539fe0456b9d6414f149981ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "wavs_path = glob(os.path.join('/home/lab/Documents/Human/Elevator_Sound_Classification/Test', '*', '*'))\n",
    "test_data = Data(wavs_path)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=True)\n",
    "\n",
    "shape = test_data.__getitem__(0)[0].shape\n",
    "model = Model(input_shape=(1,shape[0],shape[1]), batch_size=16, num_category=20).to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-5\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth: 7 prediction: 10\n",
      "ground truth: 16 prediction: 15\n",
      "ground truth: 14 prediction: 13\n",
      "ground truth: 17 prediction: 13\n",
      "ground truth: 16 prediction: 15\n",
      "ground truth: 2 prediction: 15\n",
      "ground truth: 8 prediction: 10\n",
      "error count 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "checkpoint = torch.load(os.path.join(os.path.abspath('.'), 'parameters.pth'))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "\n",
    "model.eval()\n",
    "count = 0\n",
    "for i, data in enumerate(test_loader):\n",
    "    x, y = data\n",
    "    batch, height, width = x.size()\n",
    "    x = x.view(batch, 1, height, width)\n",
    "    x = x.to(device, dtype=torch.float32)\n",
    "    y = y.to(device, dtype=torch.long)\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    \n",
    "\n",
    "    for b in range(batch):\n",
    "        pred = (torch.argmax(y_hat[b]) +1).item()\n",
    "        ground_truth = y[b].item()  \n",
    "        if ground_truth!= pred:\n",
    "            print(\"ground truth:\",ground_truth, 'prediction:',pred )\n",
    "            count +=1\n",
    "            \n",
    "print(\"error count\", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytoch1.5",
   "language": "python",
   "name": "pytoch1.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
